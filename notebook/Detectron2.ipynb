{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QHnVupBBn9eR"
   },
   "source": [
    "# Detectron2 Beginner's Tutorial\n",
    "\n",
    "<img src=\"https://dl.fbaipublicfiles.com/detectron2/Detectron2-Logo-Horz.png\" width=\"500\">\n",
    "\n",
    "Welcome to detectron2! This is the official colab tutorial of detectron2. Here, we will go through some basics usage of detectron2, including the following:\n",
    "* Run inference on images or videos, with an existing detectron2 model\n",
    "* Train a detectron2 model on a new dataset\n",
    "\n",
    "You can make a copy of this tutorial by \"File -> Open in playground mode\" and make changes there. __DO NOT__ request access to this tutorial.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vM54r6jlKTII"
   },
   "source": [
    "# Install detectron2"
   ]
  },
  {
   "source": [
    "# # install dependencies: \n",
    "# # !sudo apt-get update -yq && DEBIAN_FRONTEND=noninteractive apt-get install -y git vlc python-opencv curl unzip python-tk wget vlc libgl1-mesa-glx \n",
    "# !pip install pyyaml>=5.1 torch torchvision torchaudio==0.7.0 opencv-python  av\n",
    "# !pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu110/torch1.7/index.html\n",
    "\n",
    "# import torch, torchvision                                                                                                              \n",
    "# print(torch.__version__, torch.cuda.is_available())\n",
    "# !gcc --version\n",
    "# # opencv is pre-installed on colab"
   ],
   "cell_type": "code",
   "metadata": {
    "id": "9_FzH13EjseR"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HUjkwRsOn1O0"
   },
   "outputs": [],
   "source": [
    "# cfg = get_cfg()\n",
    "# # add project-specific config (e.g., TensorMask) here if you're not running a model in detectron2's core library\n",
    "# cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "# cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model\n",
    "# # Find a model from detectron2's model zoo. You can use the https://dl.fbaipublicfiles... url as well\n",
    "# cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
    "# predictor = DefaultPredictor(cfg)\n",
    "# outputs = predictor(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b-i4hmGYk1dL"
   },
   "outputs": [],
   "source": [
    "# # install detectron2: (Colab has CUDA 10.1 + torch 1.7)\n",
    "# # See https://detectron2.readthedocs.io/tutorials/install.html for instructions\n",
    "# import torch\n",
    "# assert torch.__version__.startswith(\"1.7\")\n",
    "# # exit(0)  # After installation, you need to \"restart runtime\" in Colab. This line can also restart runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !mkdir -p dataset\n",
    "# %cd dataset\n",
    "# !curl -L \"https://app.roboflow.com/ds/0B7BgH0Prx?key=AfYsS8tajq\" > roboflow.zip; unzip -o roboflow.zip > /dev/null; rm roboflow.zip\n",
    "# %cd -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some basic setup:\n",
    "# Setup detectron2 logger\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "import torch\n",
    "\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "from detectron2.data.datasets.coco import load_coco_json\n",
    "DatasetCatalog.clear()\n",
    "DatasetCatalog.register(\"beers_test\", lambda: load_coco_json(\"dataset/test/_annotations.coco.json\", \"dataset/test\"))\n",
    "DatasetCatalog.register(\"beers_train\", lambda: load_coco_json(\"dataset/train/_annotations.coco.json\", \"dataset/train\"))\n",
    "DatasetCatalog.register(\"beers_valid\", lambda: load_coco_json(\"dataset/valid/_annotations.coco.json\", \"dataset/valid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"Geladeira\", \"aguacrystal200ml\", \"delvallegoiaba290ml\",\"delvallemaracuja290ml\",\"delvalleuva290ml\", \"leaoguarana300ml\",\"leaoguaranaacai300ml\", \"monsterenergy473ml\", \"pratslaranja900ml\",\"toddynho150ml\"]\n",
    "MetadataCatalog.get(\"beers_train\").set(thing_classes= classes)\n",
    "MetadataCatalog.get(\"beers_test\").set(thing_classes= classes)\n",
    "MetadataCatalog.get(\"beers_valid\").set(thing_classes= classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the object labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "UkNbUzUOLYf0",
    "outputId": "130e008d-054c-4753-b591-4ae475e93f20"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from detectron2.utils.visualizer import ColorMode\n",
    "\n",
    "dataset_dicts = DatasetCatalog.get(\"beers_valid\")\n",
    "meta_valid = MetadataCatalog.get(\"beers_valid\")\n",
    "# plt.style.use(\"dark_background\")\n",
    "# fm = plt.get_current_fig_manager()\n",
    "# fm.toolbar.pan()\n",
    "\n",
    "\n",
    "for d in random.sample(dataset_dicts, 15):\n",
    "    img = cv2.imread(d[\"file_name\"])\n",
    "    visualizer = Visualizer(img[:, :, ::-1], metadata=meta_valid, scale=0.8, instance_mode=ColorMode.IMAGE_BW)\n",
    "\n",
    "    vis = visualizer.draw_dataset_dict(d)\n",
    "    test_img = vis.get_image()[:, :, ::-1]\n",
    "\n",
    "    plt.figure(figsize=(15,15))\n",
    "    plt.imshow(test_img)\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wlqXIXXhW8dA"
   },
   "source": [
    "## Train!\n",
    "\n",
    "Now, let's fine-tune a COCO-pretrained R50-FPN Mask R-CNN model on the balloon dataset. It takes ~6 minutes to train 300 iterations on Colab's K80 GPU, or ~2 minutes on a P100 GPU.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    import torch\n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7unkuuiqLdqd",
    "outputId": "af8474d6-4c32-4afe-84ac-9da260aba77b",
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "from detectron2.engine import DefaultTrainer\n",
    "\n",
    "cfg = get_cfg()\n",
    "\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\"))\n",
    "# cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/rpn_R_50_FPN_1x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"beers_train\", \"beers_test\")\n",
    "cfg.DATASETS.TEST = () #\"beers_test\",)\n",
    "cfg.TEST.EVAL_PERIOD = 50\n",
    "cfg.DATALOADER.NUM_WORKERS = 4\n",
    "# cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/rpn_R_50_FPN_1x.yaml\")  # Let training initialize from model zoo\n",
    "# cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
    "cfg.MODEL.WEIGHTS = \"detectron2://COCO-Detection/faster_rcnn_R_101_FPN_3x/137851257/model_final_f6e8b1.pkl\"\n",
    "cfg.SOLVER.IMS_PER_BATCH = 3\n",
    "cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\n",
    "cfg.SOLVER.MAX_ITER = 10000    #adjust up if val mAP is still rising, adjust down if overfit\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 256   # faster, and good enough for this toy dataset (default: 512)\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(classes)  # only has one class (ballon). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "trainer = DefaultTrainer(cfg)                                           \n",
    "trainer.resume_or_load(resume=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Look at training curves in tensorboard:\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate its performance using AP metric implemented in COCO API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "#print(\"cfg: \", cfg)\n",
    "evaluator = COCOEvaluator(\"beers_valid\", cfg, False, output_dir=\"./output/\")\n",
    "#print(\"Eval: \", eval)\n",
    "val_loader = build_detection_test_loader(cfg, \"beers_valid\")\n",
    "#print(\"Val: \", val_loader)\n",
    "inference_on_dataset(trainer.model, val_loader, evaluator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0e4vdDIOXyxF"
   },
   "source": [
    "## Inference & evaluation using the trained model\n",
    "Now, let's run inference with the trained model on the balloon validation dataset. First, let's create a predictor using the model we just trained:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ya5nEuMELeq8"
   },
   "outputs": [],
   "source": [
    "# Inference should use the config with parameters that are used in training\n",
    "# cfg now already contains everything we've set previously. We changed it a little bit for inference:\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set a custom testing threshold\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qWq1XHfDWiXO"
   },
   "source": [
    "Then, we randomly select several samples to visualize the prediction results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from detectron2.utils.visualizer import ColorMode\n",
    "\n",
    "dataset_dicts = DatasetCatalog.get(\"beers_valid\")\n",
    "meta_valid = MetadataCatalog.get(\"beers_valid\")\n",
    "\n",
    "for d in random.sample(dataset_dicts, 15):\n",
    "    img = cv2.imread(d[\"file_name\"])\n",
    "    outputs = predictor(img)\n",
    "    v = Visualizer(img[:, :, ::-1], metadata=meta_valid, scale=0.8, instance_mode=ColorMode.IMAGE_BW)\n",
    "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(15,15))\n",
    "    plt.imshow(out.get_image()[:, :, ::-1])\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert video to image frame\n",
    "!mkdir -p /home/rubio/facebook/detectron2/notebook/output/video2image\n",
    "!rm  /home/rubio/facebook/detectron2/notebook/output/video2image/*jpg\n",
    "!ffmpeg  -i \"/home/rubio/Downloads/video-30fps.mp4\" -r 1 /home/rubio/facebook/detectron2/notebook/output/video2image/image_%03d.jpg #-hide_banner -loglevel error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import cv2\n",
    "import glob\n",
    "\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "from detectron2.utils.visualizer import ColorMode\n",
    "\n",
    "for imageName in glob.glob('/home/rubio/facebook/detectron2/notebook/output/video2image/*jpg'):\n",
    "  img = cv2.imread(imageName)\n",
    "  outputs = predictor(img)  \n",
    "  v = Visualizer(img[:, :, ::-1],\n",
    "                metadata=meta_valid, \n",
    "                scale=0.8\n",
    "                # instance_mode=ColorMode.IMAGE_BW\n",
    "                 )\n",
    "  out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "  plt.figure(figsize=(15,15))\n",
    "  plt.imshow(out.get_image()[:, :, ::-1])\n",
    "  plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 322
    },
    "id": "YU5_W8wJF02F",
    "outputId": "9187dd9b-3798-4e59-926c-ff10849920c2"
   },
   "outputs": [],
   "source": [
    "# # This is the video we're going to process\n",
    "from IPython.display import YouTubeVideo, display\n",
    "# video = YouTubeVideo(\"ll8TgCZ0plk\", width=500)\n",
    "# display(video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model.cfg', 'w+') as f:\n",
    "    f.write(cfg.dump())\n",
    "!cat model.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cyA4VmKcF61k",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run frame-by-frame inference demo on this video (takes 3-4 minutes) with the \"demo.py\" tool we provided in the repo.\n",
    "# !git clone https://github.com/facebookresearch/detectron2\n",
    "!python3 ../demo/demo.py --config-file model.cfg  --confidence-threshold 0.5 \\\n",
    " --output video-output2.mkv \\\n",
    "--video-input \"/home/rubio/Downloads/WhatsApp Video 2021-01-28 at 12.41.13.mp4\" \\\n",
    " --opts MODEL.WEIGHTS output/model_final.pth \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Detectron2 Tutorial.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}